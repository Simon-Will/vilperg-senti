Produkte mit den meisten Reviews (Bücher: Harry Potter, CDs, Filme, Amazon Kindle)
außerdem Produkte mit weniger Reviews (Levi Jeans, MacBook,..
Daten mit Perl Script gecrawlt
entscheidet sich gegen Klassifizierung mit 1-5 Sternen
stattdessen: 1 und Sterne: negative -> score 0; 5 Sterne: positiv -> score:1
-> Wollte Zahl der positiven Reviews einschränken, da die oft bewerteten Produkte zum größten Teil sehr positiv bewertet werden
wir haben dieses Problem mit balancierten Chunks gelöst
baseline 50%
feature extraction:
bag of words: extrahiert 2000 häufigste Wörter aus seinen Daten
Vergleicht für jeden Review vorkommen von Wörtern in dieser Liste
binary feature vektor: 0 wenn Wort in nicht im Review vorkommt, 1 wenn es vorkommt
collocations: 'bigram function' von NLTK -> 500 häufigste Bigramme in Liste, dann analog zu bag of words
negation: folgende 3 Wörter nach eine Negation werden mit (NOT) annotiert
sentence length: Hypothese: negative Reviews enthalten kürzere Sätze -> sentence feature für kurze Sätze (>10) und für lange Sätze(>20)


Naive Bayes: Amazon Kindle (84%), MacBook (88.2%)
